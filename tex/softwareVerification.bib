@inproceedings{Anand2008,
author = {Anand, Saswat and Godefroid, Patrice and Tillmann, Nikolai},
booktitle = {Proceedings of the 14th International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS)},
file = {:C$\backslash$:/Users/leostrakosch/Copy/Documents/Informatik/Software Verification/Demand-Driven Compositional Symbolic Execution - Anand 2008.pdf:pdf},
pages = {368--381},
title = {{Demand-Driven Compositional Symbolic Execution}},
year = {2008}
}
@inproceedings{Ball2001,
abstract = {We show how to attack the problem of model checking a C program with recursive procedures using an abstraction that we formally define as the composition of the Boolean and the Cartesian abstractions. It is implemented through a source-to-source transformation into a ‘Boolean’ C program; we give an algorithm to compute the transformation with a cost that is exponential in its theoretical worst-case complexity but feasible in practice.},
author = {Ball, Tom and Podelski, Andreas and Rajamani, Sriram K.},
booktitle = {Proceedings of the 7th International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS)},
year={2002},
isbn={978-3-540-41865-8},
volume={2031},
series={LNCS},
doi={10.1007/3-540-45319-9_19},
title={Boolean and Cartesian Abstraction for Model Checking C Programs},
url={http://dx.doi.org/10.1007/3-540-45319-9_19},
publisher={Springer Berlin Heidelberg},
pages={268-283}
}
@book{BeyerBook,
author = {Beyer, Dirk and Gulwani, Sumit and Schmidt, David A},
file = {:C$\backslash$:/Users/leostrakosch/Copy/Documents/Informatik/WS 14 15/Software Verification/Software Verification.pdf:pdf},
pages = {1--50},
title = {{Combining Model Checking and Data-Flow Analysis}},
note = {To be released}
}
@inproceedings{Beyer2010,
abstract = {Several successful software model checkers are based on a technique called single-block encoding (SBE), which computes costly predicate abstractions after every single program operation. Large-block encoding (LBE) computes abstractions only after a large number of operations, and it was shown that this significantly improves the verification performance. In this work, we present adjustable-block encoding (ABE), a unifying framework that allows to express both previous approaches. In addition, it provides the flexibility to specify any block size between SBE and LBE, and also beyond LBE, through the adjustment of one single parameter. Such a unification of different concepts makes it easier to understand the fundamental properties of the analysis, and makes the differences of the variants more explicit. We evaluate different configurations on example C programs, and identify one that is currently the best.},
author = {Beyer, Dirk and Keremoglu, M. Erkan and Wendler, Philipp},
file = {:C$\backslash$:/Users/leostrakosch/Copy/Documents/Informatik/Software Verification/2010-FMCAD.Predicate\_Abstraction\_with\_Adjustable-Block\_Encoding.pdf:pdf},
isbn = {978-1-4577-0734-6},
title = {Predicate Abstraction with Adjustable-Block Encoding},
booktitle = {Proceedings of the 10th International Conference on Formal Methods in Computer-Aided Design (FMCAD)},
publisher = {FMCAD},
pages = {189-197},
year = {2010}
}
@inproceedings{Beyer2011,
abstract = {Configurable software verification is a recent concept for expressing different program analysis and model checking approaches in one single formalism. This paper presents CPAchecker, a tool and framework that aims at easy integration of new verification components. Every abstract domain, together with the corresponding operations, is required to implement the interface of configurable program analysis (CPA). The main algorithm is configurable to perform a reachability analysis on arbitrary combinations of existing CPAs. The major design goal during the development was to provide a framework for developers that is flexible and easy to extend. We hope that researchers find it convenient and productive to implement new verification ideas and algorithms using this platform and that it advances the field by making it easier to perform practical experiments. The tool is implemented in Java and runs as command-line tool or as Eclipse plug-in. We evaluate the efficiency of our tool on benchmarks from the software model checker BLAST. The first released version of CPAchecker implements CPAs for predicate abstraction, octagon, and explicit-value domains. Binaries and the source code of CPAchecker are publicly available as free software.},
archivePrefix = {arXiv},
arxivId = {0902.0019},
author = {Beyer, Dirk and Keremoglu, M. Erkan},
doi = {10.1007/978-3-642-22110-1\_16},
eprint = {0902.0019},
file = {:C$\backslash$:/Users/leostrakosch/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Beyer, Keremoglu - 2011 - CPAchecker A tool for configurable software verification.pdf:pdf},
isbn = {9783642221095},
issn = {03029743},
booktitle = {Proceedings of the 23rd International Conference on Computer Aided Verification (CAV)},
pages = {184--190},
publisher = {Springer},
series = {LNCS},
title = {{CPAchecker: A tool for configurable software verification}},
volume = {6806},
year = {2011}
}
@inproceedings{Beyer2012,
abstract = {CEGAR, SMT solving, and Craig interpolation are$\backslash$nsuccessful approaches for software model checking. We compare$\backslash$ntwo of the most important algorithms that are based on these$\backslash$ntechniques: lazy predicate abstraction (as in B LAST) and lazy$\backslash$nabstraction with interpolants (as in I MPACT). We unify the algo-$\backslash$nrithms formally (by expressing both in the CPA framework) as$\backslash$nwell as in practice (by implementing them in the same tool). This$\backslash$nallows us to flexibly experiment with new configurations and gain$\backslash$nnew insights, both about their most important differences and$\backslash$ncommonalities, as well as about their performance characteristics.$\backslash$nWe show that the essential contribution of the I MPACT algorithm$\backslash$nis the reduction of the number of refinements, and compare this$\backslash$nto another approach for reducing refinement effort: adjustable-$\backslash$nblock encoding (ABE).},
author = {Beyer, Dirk and Wendler, Philipp},
booktitle = {Proceedings of the 12th International Conference on Formal Methods in Computer-Aided Design (FMCAD)},
file = {:C$\backslash$:/Users/leostrakosch/Copy/Documents/Informatik/Software Verification/2012-FMCAD.Algorithms\_for\_Software\_Model\_Checking.pdf:pdf},
isbn = {978-1-4673-4832-4},
pages = {106--113},
publisher = {FMCAD},
title = {{Algorithms for Software Model Checking: Predicate Abstraction vs. IMPACT}},
year = {2012}
}
@inproceedings{Beyer2013,
author = {Beyer, Dirk and L\"{o}we, Stefan},
doi = {10.1007/978-3-642-37057-1\_11},
file = {:C$\backslash$:/Users/leostrakosch/Copy/Documents/Informatik/Software Verification/2013-FASE.Explicit-State\_Software\_Model\_Checking\_Based\_on\_CEGAR\_and\_Interpolation.pdf:pdf},
isbn = {9783642370564},
issn = {03029743},
booktitle = {Proceedings of the 16th International Conference on Fundamental Approaches to Software Engineering (FASE)},
pages = {146--162},
title = {{Explicit-state software model checking based on CEGAR and interpolation}},
year = {2013},
publisher = {Springer},
series = {LNCS},
volume = {7793}
}
@inproceedings{Beyer2015,
author = {Dirk Beyer and Stefan L{\"o}we and Philipp Wendler},
title = {Sliced Path Prefixes: An Effective Method to Enable Refinement Selection},
booktitle = {Proceedings of the 10th International Conference on Distributed Computing Techniques (FORTE)},
publisher = {Springer},
series = {LNCS},
volume = {9039},
pages = {228-243},
year = {2015},
}
@InProceedings{Beyer2015a,
  author     = {D.~Beyer and S.~L{\"o}we and P.~Wendler},
  title      = {Refinement Selection},
  booktitle  = {Proc.\ SPIN},
  publisher  = {Springer},
  series     = {LNCS},
  pages      = {},
  year       = {2015},
  note = {To be released}
}
@article{Beyer2007,
abstract = {In automatic software verification, we have observed a theoretical convergence of model checking and program analysis. In practice, however, model checkers are still mostly concerned with precision, e.g., the removal of spurious counterexamples; for this purpose they build and refine reachability trees. Lattice-based program analyzers, on the other hand, are primarily concerned with efficiency. We designed an algorithm and built a tool that can be configured to perform not only a purely tree-based or a purely lattice-based analysis, but offers many intermediate settings that have not been evaluated before. The algorithm and tool take one or more abstract interpreters, such as a predicate abstraction and a shape analysis, and configure their execution and interaction using several parameters. Our experiments show that such customization may lead to dramatic improvements in the precision-efficiency spectrum.},
author = {Beyer, Dirk and Henzinger, Thomas A. and Th\'{e}oduloz, Gr\'{e}gory},
doi = {10.1007/978-3-540-73368-3\_51},
file = {:C$\backslash$:/Users/leostrakosch/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Beyer, Henzinger, Th\'{e}oduloz - 2007 - Configurable Software Verification Concretizing the Convergence of Model Checking and Program Analy.pdf:pdf},
isbn = {978-3-540-73367-6},
issn = {03029743},
journal = {Proceedings of the 19th International Conference on Computer Aided Verification (CAV)},
pages = {504--518},
title = {{Configurable Software Verification: Concretizing the Convergence of Model Checking and Program Analysis}},
volume = {4590},
publisher = {Springer},
series = {LNCS},
year = {2007}
}
@inproceedings{Beyer2008,
author = {Beyer, Dirk and Henzinger, Thomas A. and Th\'{e}oduloz, Gr\'{e}gory},
title = {Program Analysis with Dynamic Precision Adjustment},
booktitle = {Proceedings of the 23rd IEEE/ACM International Conference on Automated Software Engineering (ASE)},
publisher={IEEE Computer Society Press},
pages = {29-38},
year={2008}
}
@inproceedings{Burnim2008,
author = {Burnim, J and Sen, K},
doi = {http://dx.doi.org/10.1109/ASE.2008.69},
file = {:home/leostrakosch/Documents/Informatik/Software Verification/Burnim Heuristics for Dynamic Test GEneration - CREST.pdf:pdf},
isbn = {978-1-4244-2187-9},
booktitle = {Proceedings of the 2008 23rd IEEE/ACM International Conference on Automated Software Engineering (ASE)},
pages = {443--446},
publisher = {IEEE Computer Society},
series = {ASE~'08},
title = {{Heuristics for Scalable Dynamic Test Generation}},
year = {2008}
}
@inproceedings{Cadar2008,
abstract = {We present a new symbolic execution tool, KLEE, capable of automatically generating tests that achieve high coverage on a diverse set of complex and environmentally-intensive programs. We used KLEE to thoroughly check all 89 stand-alone programs in the GNU COREUTILS utility suite, which form the core user-level environment installed on millions of Unix systems, and arguably are the single most heavily tested set of open-source programs in existence. KLEE-generated tests achieve high line coverage - on average over 90\% per tool (median: over 94\%) - and significantly beat the coverage of the developers' own hand-written test suite. When we did the same for 75 equivalent tools in the BUSYBOX embedded system suite, results were even better, including 100\% coverage on 31 of them. We also used KLEE as a bug finding tool, applying it to 452 applications (over 430K total lines of code), where it found 56 serious bugs, including three in COREUTILS that had been missed for over 15 years. Finally, we used KLEE to crosscheck purportedly identical BUSYBOX and COREUTILS utilities, finding functional correctness errors and a myriad of inconsistencies.},
author = {Cadar, Cristian and Dunbar, Daniel and Engler, Dawson R.},
booktitle = {Proceedings of the 8th USENIX conference on Operating systems design and implementation},
doi = {10.1.1.142.9494},
file = {:home/leostrakosch/Documents/Informatik/Software Verification/Cadar - KLEE.pdf:pdf},
isbn = {978-1-931971-65-2},
issn = {<null>},
pages = {209--224},
series = {OSDI},
volume = {8},
title = {{KLEE: Unassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs}},
url = {http://portal.acm.org/citation.cfm?id=1855756},
year = {2008}
}
@inproceedings{Chu2014,
author = {Chu, Duc-hiep and Jaffar, Joxan and Murali, Vijayaraghavan},
booktitle = {Proceedings of the 5th International Conference on Runtime Verification},
file = {:home/leostrakosch/Documents/Informatik/Software Verification/Lazy symbolic execution for enhanced learning.pdf:pdf},
keywords = {interpolation},
mendeley-tags = {interpolation},
pages = {323--339},
title = {{Lazy Symbolic Execution for Enhanced Learning}},
year = {2014},
publisher = {Springer},
series = {LNCS},
volume = {8734}
}
@article{Clarke2003,
abstract = {The state explosion problem remains a major hurdle in applying symbolic model checking to large hardware designs. State space abstraction, having been essential for verifying designs of industrial complexity, is typically a manual process, requiring considerable creativity and insight.In this article, we present an automatic iterative abstraction-refinement methodology that extends symbolic model checking. In our method, the initial abstract model is generated by an automatic analysis of the control structures in the program to be verified. Abstract models may admit erroneous (or "spurious") counterexamples. We devise new symbolic techniques that analyze such counterexamples and refine the abstract model correspondingly. We describe aSMV, a prototype implementation of our methodology in NuSMV. Practical experiments including a large Fujitsu IP core design with about 500 latches and 10000 lines of SMV code confirm the effectiveness of our approach.},
author = {Clarke, Edmund and Grumberg, Orna and Jha, Somesh and Lu, Yuan and Veith, Helmut},
doi = {10.1145/876638.876643},
file = {:C$\backslash$:/Users/leostrakosch/Copy/Documents/Informatik/Software Verification/2003-ACM.Counterexample-Guided Abstraction Refinement for Symbolic Model Checking.pdf:pdf},
issn = {0004-5411},
journal = {Journal of the ACM},
number = {5},
pages = {752--794},
title = {{Counterexample-guided abstraction refinement for symbolic model checking}},
url = {http://portal.acm.org/citation.cfm?id=876643$\backslash$nhttp://portal.acm.org/ft\_gateway.cfm?id=876643\&type=pdf\&coll=GUIDE\&dl=GUIDE\&CFID=45815308\&CFTOKEN=61927748},
volume = {50},
year = {2003}
}
@article{Craig1957,
author = {Craig, William},
journal = {The Journal of Symbolic Logic},
number = {3},
pages = {250--268},
title = {{Linear Reasoning. A new form of the Herbrand-Gentzen theorem}},
volume = {22},
year = {1957}
}
@inproceedings{Friedberger2015,
author = {Beyer, Dirk and Friedberger, Karlheinz},
title = {{BAM Interprocedural: Domain-Independent Verification of Recursive Programs using Block-Abstraction Memoization}},
booktitle = {Proc. FMAC},
year = {2015},
note = {To be released}
}
@inproceedings{Godefroid2005,
author = {Godefroid, Patrice and Klarlund, Nils and Sen, Koushik},
booktitle = {Proceedings of the 2005 ACM SIGPLAN Conference on Programming Language Design and Implementation},
doi = {10.1145/1064978.1065036},
file = {:home/leostrakosch/Documents/Informatik/Software Verification/Godefroid 2005 - DART directed automated random testing (concolic).pdf:pdf},
isbn = {1-59593-056-6},
issn = {03621340},
keywords = {automated test generation,concolic,interfaces,program verification,random testing,software testing},
mendeley-tags = {concolic},
title = {{Dart: Directed Automated Random Testing}},
url = {http://dl.acm.org/citation.cfm?id=1064978.1065036},
year = {2005},
series = {PLDI '05},
publisher = {ACM}
}
@inproceedings{Godefroid2007,
author = {Godefroid, Patrice},
booktitle = {Proceedings of the 34th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
doi = {10.1145/1190216.1190226},
file = {:home/leostrakosch/Documents/Informatik/Software Verification/Godefroid - Compositional dynamic test generation.pdf:pdf},
isbn = {1-59593-575-4},
issn = {03621340},
keywords = {automatic test generation,compositional,compositional program analysis,program verification,scalability,software testing},
mendeley-tags = {compositional},
pages = {47--54},
title = {{Compositional Dynamic Test Generation}},
url = {http://doi.acm.org/10.1145/1190216.1190226},
year = {2007},
publisher = {ACM},
series = {POPL '07}
}
@inproceedings{Henzinger2002,
author = {Henzinger, Thomas A. and Majumdar, Rupak and Sutre, Gregoire},
booktitle = {Proceedings of the 29th SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
file = {:home/leostrakosch/Documents/Informatik/Software Verification/Henzinger Lazy Abstraction 2002.pdf:pdf},
isbn = {1581134509},
pages = {58--70},
title = {{Lazy Abstraction}},
year = {2002},
publisher = {ACM},
series = {POPL '02}
}
@inproceedings{Henzinger2004,
author = {Henzinger, Thomas A. and Jhala, Ranjit and Majumdar, Rupak and McMillan, Kenneth L.},
booktitle= {Proceedings of the 31st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
pages = {232--244},
title = {{Abstractions from Proofs}},
year = {2004},
publisher = {ACM},
series = {POPL '04}
}
@article{Jaffar1992,
author = {Jaffar, Joxan and Michaylov, Spiro and Stuckey, Peter J. and Yap, Roland H. C.},
journal = {ACM Transactions on Programming Languages and Systems (TOPLAS)},
keywords = {interpolation},
mendeley-tags = {interpolation},
number = {3},
pages = {339--395},
title = {{The CLP(R) language and system}},
volume = {14},
year = {1992}
}
@inproceedings{Jaffar2009,
author = {Jaffar, Joxan and Santosa, Andrew and Voicu, Razvan},
booktitle = {Proceedings of the 15th International Conference on Principles and Practice of Constraint Programming (CP)},
file = {:home/leostrakosch/Documents/Informatik/Software Verification/Jaffar 2009 CLP Interpolation.pdf:pdf},
keywords = {interpolation},
mendeley-tags = {interpolation},
pages = {454--469},
title = {{An Interpolation Method for CLP Traversal}},
year = {2009},
publisher = {Springer},
series = {LNCS},
volume = {5732}
}
@inproceedings{Jaffar2012,
author = {Jaffar, Joxan and Navas, Jorge a. and Santosa, Andrew E.},
booktitle = {Proceedings of the 2nd International Conference on Runtime Verification (RV)},
doi = {10.1007/978-3-642-29860-8\_32},
file = {:home/leostrakosch/Documents/Informatik/Software Verification/Tracer - Unbounded SE.pdf:pdf},
isbn = {9783642298592},
issn = {03029743},
pages = {396--411},
title = {{Unbounded symbolic execution for program verification}},
volume = {7186},
series = {LNCS},
publisher = {Springer},
year = {2012}
}
@inproceedings{Jaffar2012a,
abstract = {We present TRACER, a verifier for safety properties of sequential C programs. It is based on symbolic execution (SE) and its unique features are in how it makes SE finite in presence of unbounded loops and its use of interpolants from infeasible paths to tackle the path-explosion problem.},
author = {Jaffar, Joxan and Murali, Vijayaraghavan and Navas, Jorge a. and Santosa, Andrew E.},
booktitle = {Proceedings of the 24th International Conference on Computer Aided Verification},
doi = {10.1007/978-3-642-31424-7\_61},
file = {:home/leostrakosch/Documents/Informatik/Software Verification/TRACER\_CAV12.pdf:pdf},
isbn = {9783642314230},
issn = {03029743},
pages = {758--766},
title = {{TRACER: A symbolic execution tool for verification}},
year = {2012},
publisher = {Springer},
series = {LNCS},
volume = {7358}
}
@inproceedings{Jaffar2013,
abstract = {Concolic testing has been very successful in automatically generating test inputs for programs. However one of its major limitations is path-explosion that limits the generation of high coverage inputs. Since its inception several ideas have been proposed to attack this problem from various angles: defining search heuristics that increase coverage, caching of function summaries, pruning of paths using static/dynamic information etc. We propose a new and complementary method based on interpolation, that greatly mitigates path-explosion by subsuming paths that can be guaranteed to not hit a bug. We discuss new challenges in using interpolation that arise specifically in the context of concolic testing. We experimentally evaluate our method with different search heuristics using Crest, a publicly available concolic tester.},
author = {Jaffar, Joxan and Murali, Vijayaraghavan and Navas, Jorge a.},
booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering - ESEC/FSE 2013},
doi = {10.1145/2491411.2491425},
file = {:home/leostrakosch/Documents/Informatik/Software Verification/Interpolation with CREST.pdf:pdf},
isbn = {9781450322379},
keywords = {Concolic testing,interpolation,symbolic execution},
mendeley-tags = {interpolation},
pages = {48},
title = {{Boosting concolic testing via interpolation}},
url = {http://dl.acm.org/citation.cfm?id=2491411.2491425},
year = {2013},
publisher = {ACM},
series = {ESEC/FSE 2013}
}
@techreport{Lemberger2015,
address = {Passau},
author = {Lemberger, Thomas},
file = {:C$\backslash$:/Users/leostrakosch/Copy/Documents/Informatik/Software Verification/SymEx\_in\_CPAchecker.pdf:pdf},
institution = {Chair of Software Systems, University of Passau},
title = {{Symbolic Execution in CPAChecker}},
url = {http://leostrakosch.github.io/symbolicValueAnalysis/SymEx\_in\_CPAchecker.pdf},
year = {2015}
}
@inproceedings{Majumdar2007,
abstract = {We present hybrid concolic testing, an algorithm that interleaves random testing with concolic execution to obtain both a deep and a wide exploration of program state space. Our algorithm generates test inputs automatically by interleaving random testing until saturation with bounded exhaustive symbolic exploration of program points. It thus combines the ability of random search to reach deep program states quickly together with the ability of concolic testing to explore states in a neighborhood exhaustively. We have implemented our algorithm on top of CUTE and applied it to obtain better branch coverage for an editor implementation (VIM 5.7, 150 K lines of code) as well as a data structure implementation in C. Our experiments suggest that hybrid concolic testing can handle large programs and provide, for the same testing budget, almost 4times the branch coverage than random testing and almost 2times that of concolic testing.},
author = {Majumdar, Rupak and Sen, Koushik},
booktitle = {Proceedings of the 29th International Conference on Software Engineering (ICSE)},
doi = {10.1109/ICSE.2007.41},
file = {:home/leostrakosch/Documents/Informatik/Software Verification/Majumdar - Hybrid Concolic Testing.pdf:pdf},
isbn = {0769528287},
issn = {02705257},
keywords = {Concolic testing,Directed random testing,concolic},
mendeley-tags = {concolic},
pages = {416--425},
title = {{Hybrid concolic testing}},
year = {2007}
}
@inproceedings{McMillan2010,
author = {McMillan, Kenneth L},
booktitle = {Proceedings of the 22nd International Conference on Computer Aided Verification},
file = {:home/leostrakosch/Documents/Informatik/Software Verification/McMillan Lazy Annotation.pdf:pdf},
pages = {104--118},
title = {{Lazy Annotation for Program Testing and Verification}},
year = {2010},
publisher = {Springer},
series = {LNCS},
volume = {6174}
}
@article{King1976,
abstract = {This paper describes the symbolic execution of programs. Instead of supplying the normal inputs to a program (e.g. numbers) one supplies symbols representing arbitrary values. The execution proceeds as in a normal execution except that values may be symbolic formulas over the input symbols. The difficult, yet interesting issues arise during the symbolic execution of conditional branch type statements. A particular system called EFFIGY which provides symbolic execution for program testing and debugging is also described. It interpretively executes programs written in a simple PL/I style programming language. It includes many standard debugging features, the ability to manage and to prove things about symbolic expressions, a simple program testing manager, and a program verifier. A brief discussion of the relationship between symbolic execution and program proving is also included.},
author = {King, James C.},
doi = {10.1145/360248.360252},
file = {:home/leostrakosch/Documents/Informatik/Software Verification/Classic SE.pdf:pdf},
isbn = {0001-0782},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {and phrases,pro-,symbolic execution},
number = {7},
pages = {385--394},
title = {{Symbolic Execution and Program Testing}},
volume = {19},
year = {1976}
}
@book{Myers2011,
author = {Myers, Glenford J. and Sandler, Corey and Badgett, Tom},
edition = {3rd},
publisher = {John Wiley \& Sons},
title = {{The Art of Software Testing}},
year = {2011}
}
@inproceedings{Sen2005,
author = {Sen, Koushik and Marinov, Darko and Agha, Gul},
booktitle = {Proceedings of the 10th European software engineering conference held jointly with 13th ACM SIGSOFT international symposium on Foundations of software engineering (ESEC/FSE)},
doi = {10.1145/1081706.1081750},
file = {:home/leostrakosch/Documents/Informatik/Software Verification/Sen 2005 - CUTE$\backslash$: A Concolic Unit Testing Engine.pdf:pdf},
isbn = {1595930140},
issn = {0163-5948},
keywords = {concolic,concolic testing,data structure testing,explicit path model-checking,random testing,testing C programs,unit testing},
mendeley-tags = {concolic},
number = {5},
pages = {263},
title = {{Cute: A Concolic Unit Testing Engine for C}},
url = {http://dl.acm.org/citation.cfm?id=1081706.1081750},
volume = {30},
year = {2005},
publisher = {ACM},
series = {ESEC/FSE-13}
}
@inproceedings{Slaby2013,
author = {Slaby, Jiri and Strejcek, Jan and Trtik, Marek},
booktitle = {Proceedings of the 11th International Symposium on Automated Technology for Verification and Analysis (ATVA)},
file = {:home/leostrakosch/Documents/Informatik/Software Verification/2013-ATVA.Compact Symbolic Execution - Slaby.pdf:pdf},
pages = {193--207},
title = {{Compact Symbolic Execution}},
year = {2013},
publisher = {Springer},
series = {LNCS},
volume = {8172}
}
@misc{SV15Benchmark,
author = {Beyer, Dirk},
title = {{Competition on Software Verification (SV-COMP) 2015: Benchmark Verification Tasks}},
url = {http://sv-comp.sosy-lab.org/2015/benchmarks.php},
urldate = {2015-03-07},
year = {2015}
}
@inproceedings{SV-COMP2013,
author = {Beyer, Dirk},
title = {{Second Competition on Software Verification (Summary of SV-COMP 2013)}},
booktitle = {Proc. TACAS},
series = {LNCS},
volume = {7795},
pages = {594--609},
publisher = {Springer},
year = {2013}
}
@inproceedings{SV-COMP2014,
author = {Beyer, Dirk},
title = {{Status Report on Software Verification (Competition Summary SV-COMP 2014)}},
booktitle = {Proc. TACAS},
series = {LNCS},
volume = {8413},
pages = {373--388},
publisher = {Springer},
year = {2014}
}
@inproceedings{SV-COMP2015,
author = {Beyer, Dirk},
title = {{Software Verification and Verifiable Witnesses (Report on SV-COMP 2015)}},
booktitle = {Proc. TACAS},
series = {LNCS},
publisher = {Springer},
year = {2015},
note = {(To appear)}
}
@misc{SV15Tasks,
author = {Beyer, Dirk},
title = {{SV-COMP15: Benchmark Verification Tasks}},
year = {2015},
howpublished = "\url{http://sv-comp.sosy-lab.org/2015/benchmarks.php}",
note = {Last checked: 03.31.2015}
}
