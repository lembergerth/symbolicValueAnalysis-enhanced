\section{Evaluation of CEGAR}

\subsection{Comparison to \SymbolicExecutionCPA\ without CEGAR}
Evaluation shows the great boost CEGAR provides to the \symbolicExecutionCPA. 
Table~\ref{tab:cegarBenefits} shows the results of the \symbolicExecutionCPA\ without CEGAR using the subset less-or-equal operator and $\cpaMerge^{sep}$ (SymEx w/o CEGAR), in comparison to the \symbolicExecutionCPA\ using CEGAR with refinement based on CEGAR for explicit-state model checking (SymEx w/ CEGAR, Sec.~\ref{sec:assignmentRefinement}).
\emph{Program errors} are errors in the execution of \cpaChecker, in this case a parsing error of a file for both analysis and an exception due to a failure of the SMT solver in the analysis without CEGAR and one due to a division by zero in the analysis with CEGAR.
The increase in correctly handled tasks \emph{without} a safety violation (in the table row ''correct negatives'') by a factor of more then 10
and the decrease in timeouts by more then 40\% are the most notable improvements by using CEGAR.
On the contrary, the number of found safety violations decreases by 222 tasks,
since the lazy approach of CEGAR has a problem with programs consisting of a lot of assumptions leading to an error in dependence of many variables.

\begin{table}[t]
\begin{tabular}{|r|c|c|c|}
\hline
    & SymEx w/o CEGAR & SymEx w/ CEGAR & Overall \\ \hline
correct results & 761 (18.60\%) & 2078 (50.78\%) & 4092 \\ \hline
\resultFalse, correct & 598 (50.63\%) & 376 (31.83\%) & 1181 \\ \hline
\resultTrue, correct & 163 (5.599\%) & 1702 (58.47\%) & 2911 \\ \hline
unique \resultFalse, correct & 323 & 101 & \\ \hline
unique \resultTrue, correct & 84 & 1623 & \\ \hline
\resultFalse, incorrect & 44 & 83 & \\ \hline
unique \resultFalse, incorrect & 4 & 43 & \\ \hline
\resultTrue, incorrect & 0 & 1 & \\ \hline
program errors & 2 & 2 & \\ \hline % exception because of / 0, parsing error at both
%timeouts & 3275 & 1927 & \\ \hline
resource errors & 3285 & 1928 & \\ \hline % includes timeouts + StackOverflowException
\end{tabular}
\caption{Results of benchmark runs of the \symbolicExecutionCPA\ without CEGAR and with CEGAR}
\label{tab:cegarBenefits}
\end{table}

\begin{figure}
\begin{subfigure}[b]{.3\textwidth}
\centering
\begin{tikzpicture}[->,>=stealth, mynode/.style={rectangle, draw, minimum height=0.5cm, minimum width=0.8cm}, every node/.style={font=\small}]

\node[mynode] (0) {$\varnothing$};
\node[mynode] (1) [below = 0.6cm of 0] {$\varnothing$};
\node[mynode] (2) [below = 0.6cm of 1, draw=red, very thick] {$\varnothing$};

\path
  (0) edge node [left] {\textbf{a $\assign$ 2, b $\assign$ 2, ..., z $\assign$ 2}} (1)
  (1) edge node [left] {$\mathbf{[a == 1]}$} (2)
;
\end{tikzpicture}
\caption{First iteration, tracking no variables}
\label{fig:cegarFailsEx:first}
\end{subfigure}%
\hfill
\begin{subfigure}[b]{.3\textwidth}
\centering
\begin{tikzpicture}[->,>=stealth, mynode/.style={rectangle, draw, minimum height=0.5cm, minimum width=0.8cm}, every node/.style={font=\small}]

\node[mynode] (0) {$\varnothing$};
\node[mynode] (1) [below = 0.6cm of 0] {$\{ a \rightarrow 2 \}$};
\node[mynode] (2) [below = 0.6cm of 1] {$\{ a \rightarrow 2 \}$};
\node[mynode] (3) [below = 0.6cm of 2, draw=red, very thick] {$\{ a \rightarrow 2 \}$};

\path
  (0) edge node [left] {\textbf{a $\assign$ 2, ..., z $\assign$ 2}} (1)
  (1) edge node [left] {$\mathbf{[!(a == 1)]}$} (2)
  (2) edge node [left] {$\mathbf{[b == 1]}$} (3)
;
\end{tikzpicture}
\caption{Second iteration, tracking variable $a$}
\label{fig:cegarFailsEx:second}
\end{subfigure}%
\hfill
\begin{subfigure}[b]{.3\textwidth}
\centering
\begin{tikzpicture}[->,>=stealth, mynode/.style={rectangle, draw, minimum height=0.5cm, minimum width=0.8cm}, every node/.style={font=\small}]

\node[mynode] (0) {$\varnothing$};
\node[mynode] (1) [below = 0.6cm of 0] {$\{ a \rightarrow 2, b \rightarrow 2 \}$};
\node[mynode] (2) [below = 0.6cm of 1] {$\{ a \rightarrow 2, b \rightarrow 2 \}$};
\node[mynode] (3) [below = 0.6cm of 2] {$\{ a \rightarrow 2, b \rightarrow 2 \}$};
\node[mynode] (4) [below = 0.6cm of 3, draw=red, very thick] {$\{ a \rightarrow 2, b \rightarrow 2 \}$};

\path
  (0) edge node [left] {\textbf{a $\assign$ 2, ..., z $\assign$ 2}} (1)
  (1) edge node [left] {$\mathbf{[!(a == 1)]}$} (2)
  (2) edge node [left] {$\mathbf{[!(b == 1)]}$} (3)
  (3) edge node [left] {$\mathbf{[c == 1]}$} (4)
;
\end{tikzpicture}
\caption{Third iteration, tracking variables $a$ and $b$}
\label{fig:cegarFailsEx:third}
\end{subfigure}%
\vspace{1cm}
\begin{subfigure}[b]{.48\textwidth}
\begin{tikzpicture}[->,>=stealth, mynode/.style={circle, draw, minimum size=0.5cm}, every node/.style={font=\small}]

\node[mynode] (0) {0};
\node[mynode] (1) [below = 0.6cm of 0] {1};
\node[mynode] (l2) [below left = 0.7cm and 0.8cm of 1] {2};
\node[mynode] (r2) [below right = 0.7cm and 0.8cm of 1, draw=red, very thick] {3};
\node[mynode] (ll3) [below left = 0.7cm and 0.6cm of l2] {4};
\node[mynode] (lr3) [below right = 0.7cm and 0.6cm of l2, draw=red, very thick] {5};
\node[mynode] (llr4) [below right = 0.7cm and 0.4cm of ll3, draw=red, very thick] {6};
\node[mynode] (lll6) [below left = 2cm and 0.4cm of ll3] {7};
\node[mynode] (lllr6) [below right = 0.7cm and 0.3cm of lll6, draw=red, very thick] {9};
\node[mynode] (llll6) [below left = 0.7cm and 0.3cm of lll6] {8};

\path
  (0) edge node [left] {\textbf{a $\assign$ 2, b $\assign$ 2, ... z $\assign$ 2}} (1)
  (1) edge node [left, pos=0.3] {$\mathbf{[!(a == 1)]}$} (l2)
  (1) edge node [right, pos=0.3] {$\mathbf{[a == 1]}$} (r2)
  (l2) edge node [left, pos=0.3] {$\mathbf{[!(b == 1)]}$} (ll3)
  (l2) edge node [right, pos=0.3] {$\mathbf{[b == 1]}$} (lr3)
  (ll3) edge node [right, pos=0.3] {$\mathbf{[c == 1]}$} (llr4)
  (ll3) edge [dashed] (lll6)
  (lll6) edge node [right, pos=0.5] {$\mathbf{[z == 2]}$} (lllr6)
  (lll6) edge node [left, pos=0.5] {$\mathbf{[!(z == 2)]}$} (llll6)
;
\end{tikzpicture}
\caption{CFA}
\label{fig:cegarFailsEx:cfa}
\end{subfigure}%
\hfill
\begin{subfigure}[b]{.48\textwidth}
\centering
\begin{tikzpicture}[->,>=stealth, mynode/.style={rectangle, draw, minimum height=0.5cm, minimum width=0.8cm}, every node/.style={font=\small}]

\node[mynode] (0) {$\varnothing$};
\node[mynode] (1) [below = 0.6cm of 0] {$\{ a \rightarrow 2, b \rightarrow 2, ..., z \rightarrow 2 \}$};
\node[mynode] (2) [below = 0.6cm of 1] {$\{ a \rightarrow 2, b \rightarrow 2, ..., z \rightarrow 2 \}$};
\node[mynode] (3) [below = 0.6cm of 2 ] {$\{ a \rightarrow 2, b \rightarrow 2, ..., z \rightarrow 2 \}$};
\node[mynode] (4) [below = 2cm of 3] {$\{ a \rightarrow 2, b \rightarrow 2, ..., z \rightarrow 2 \}$};
\node[mynode] (5) [below = 0.6cm of 4, draw=red, very thick] {$\{ a \rightarrow 2, b \rightarrow 2, ..., z \rightarrow 2 \}$};

\path
  (0) edge node [left] {\textbf{a $\assign$ 2, ..., z $\assign$ 2}} (1)
  (1) edge node [left] {$\mathbf{[!(a == 1)]}$} (2)
  (2) edge node [left] {$\mathbf{[!(b == 1)]}$} (3)
  (3) edge [dashed] (4)
  (4) edge node [left] {$\mathbf{z == 2}$} (5)
;
\end{tikzpicture}
\caption{Last iteration tracking all program variables. Also equals the run of eager analysis}
\label{fig:cegarFailsEx:eager}
\end{subfigure}
%\caption{CFA representing an example program CEGAR performs worse for then eager analysis.}
%\label{fig:cegarFails}\\
\caption{A CFA representing a program CEGAR performs worse for then eager analysis and the first three
and last one iteration of analysis using CEGAR. The last iteration also equals the eager analysis.}
\label{fig:cegarFailsEx}
\end{figure}

Figure~\ref{fig:cegarFailsEx:cfa} shows a CFA representing one such program. The highlighted nodes are error locations.
Although only the last one of them is really reachable as all program variables are initialised with the concrete value $2$ at the beginning of the program,
the CEGAR algorithm visits one after the other, always refining the precision to track only one additional variable and then restarting
from the beginning of the program, since all variable assignments happen there.
The first three iterations of this procedure are shown in Figures~\ref{fig:cegarFailsEx:first} -- \ref{fig:cegarFailsEx:third}.
This lazy approach performs many computations obviously unnecessary and as such has a significant worse performance than an eager approach using full precision.
Using full precision, it is possible to prove all error paths but the last infeasible in one run, since the value analysis state already equals $\{ a \rightarrow 2, b \rightarrow 2, ..., z \rightarrow 2 \}$ after processing the first CFA edge (Fig.~\ref{fig:cegarFailsEx:eager}).
Analogous, programs like this requiring the tracking of all constraints exist and programs with such characteristics, but without a reachable target location.
Tasks of the latter category constitute almost all of the 84~unique correct \resultTrue\ results of symbolic execution without CEGAR.

\begin{figure}[t]
\begin{subfigure}[b]{.48\textwidth}
\includegraphics[trim=2cm 0 1cm 0, clip=true, scale=.9]{evaluation/sp_timeToFindError_cegar_noCegar}
\caption{Time in seconds to find an error}
\label{fig:spTimeToFindError}
\end{subfigure}%
\hfill
\begin{subfigure}[b]{.48\textwidth}
\includegraphics[trim=2cm 0 1cm 0, clip=true, scale=.9]{evaluation/sp_timeToProveTrue_cegar_noCegar}
\caption{Time in seconds to prove a program safe}
\label{fig:spTimeToProveSafe}
\end{subfigure}
\caption{Runtime performance of symbolic execution with and without CEGAR in comparison}
\end{figure}

Most of the programs with these characteristics are of the task sets of ProductLines and ECA.
To recap, of the 598~tasks symbolic execution without CEGAR can correctly find errors in, more than half (323~tasks) can't be analysed correctly by symbolic execution with CEGAR
due to many infeasible error paths and the resulting amount of refinements.
On the other hand, symbolic execution with CEGAR is able to prove for 101~new tasks that an error exists in them.
This shows that the efficiency of symbolic execution with and without CEGAR strongly depends on the task on hand, especially when the program is not error-free.
Fig.~\ref{fig:spTimeToFindError} illustrates that for many programs, either symbolic execution with or without CEGAR is able to find a (possibly non-existent) error within 900~seconds, but not both.
For proving the safety of a program, analysis with CEGAR performs significantly better, being able to correctly analyse 1623~tasks more than analysis without CEGAR, but its laziness results in bad performance for some programs, too (Fig.~\ref{fig:spTimeToProveSafe}).

\begin{figure}[h!]
\includegraphics{evaluation/hg_refinementsForUniqueCorrects}
\caption{Amount of tasks analysis with CEGAR can compute a result for while analysis without CEGAR can't, and the number of refinements necessary for them}
\label{fig:hgRefinementsForUniques}
\end{figure}
\begin{figure}[h!]
\includegraphics{evaluation/hg_refinementsForUniqueTimeouts}
\caption{Amount of refinements (up to 100) that were performed for a specific amount of tasks that resulted in a timeout}
\label{fig:hgRefinementsForTimeouts}
\end{figure}
For most tasks symbolic execution with CEGAR is able to compute a result but symbolic execution without CEGAR is not, only few or zero~refinements are necessary (Fig.~\ref{fig:hgRefinementsForUniques}).
Comparison with the random distribution of performed refinements in tasks that resulted in a timeout when using CEGAR (Fig.~\ref{fig:hgRefinementsForTimeouts}) confirms the problem CEGAR has with many possible error paths.

Nevertheless, thanks to its significant better performance in proving the safety of programs, CEGAR was able to push the \symbolicExecutionCPA's score from 660~points to 3271~points by increasing the amount of successfully verified
error-free tasks by more than~1500.

\subsection{Different interpolation techniques}
\label{sec:eval:itpTechniques}
\begin{table}[t]
\begin{tabular}{|r|c|c|c|c|}
\hline
                               & Values only & Values first & Constraints first & Overall \\ \hline
correct results                & 2080        & 2079         & 2078              & 4092 \\ \hline
\resultFalse, correct          & 378         & 376          & 376               & 2911 \\ \hline
\resultTrue, correct           & 1702        & 1703         & 1702              & 1181 \\ \hline
unique \resultFalse, correct   & 2           & 0            & 0                 & \\ \hline
unique \resultTrue, correct    & 0           & 0            & 0                 & \\ \hline
\resultFalse, incorrect        & 83          & 83           & 83                & \\ \hline
unique \resultFalse, incorrect & 0           & 0            & 0                 & \\ \hline
\resultTrue, incorrect         & 1           & 1            & 1                 & \\ \hline
unique \resultTrue, incorrect  & 0           & 0            & 0                 & \\ \hline
program errors                 & 3           & 3            & 2                 & \\ \hline % exception because of / 0, parsing error
%timeouts & 3275 & 1927 & \\ \hline
resource errors                & 1925        & 1926         & 1928              &\\ \hline % includes timeouts + StackOverflowException
\end{tabular}
\caption{Results of benchmark runs of the \symbolicExecutionCPA\ with CEGAR using three different techniques for interpolation computation}
\label{tab:itpTechniqueComp}
\end{table}
We compare three different techniques for computing interpolants of the \symbolicExecutionCPA\ already mentioned in Section~\ref{sec:assignmentRefinement}:
\begin{enumerate}[label=\alph*)]
\item Only removing unnecessary values and using all constraints that resulted from the previous interpolant and the strongest-post operator at the current edge (\emph{values only}),
\item removing unnecessary values first and then constraints (\emph{values first}), and
\item removing unnecessary constraints first and then values (\emph{constraints first}).
\end{enumerate}
Table~\ref{tab:itpTechniqueComp} shows that almost no difference exists in the effectivenes of all three techniques.
General time performance also differs in no significant way, as the scatter plots in Figure~\ref{fig:spTimeVOVF} show.
\begin{figure}[t]
\begin{subfigure}[b]{.48\textwidth}
\includegraphics[trim=2cm 0 1cm 0, clip=true, scale=.9]{evaluation/sp_valuesOnly_valuesFirst_cputime}
\end{subfigure}%
\hfill
\begin{subfigure}[b]{.48\textwidth}
\includegraphics[trim=2cm 0 1cm 0, clip=true, scale=.9]{evaluation/sp_valuesFirst_constrFirst_cputime}
\end{subfigure}
\caption{Runtime performance of different interpolation techniques over all benchmark tasks}
\label{fig:spTimeVOVF}
\end{figure}
Using the values only interpolation technique yields two more correctly found errors over all benchmark tasks.
Both tasks are close to the time limit with 863.4 and 887.5 seconds.
The successful analysis of these two tasks is a result of the faster ''values only'' interpolant computation.
Since the strongest-post operator of symbolic execution refinement uses expensive SAT checks to check the satisfiability of current constraints, the two refinement procedures
''values first'' and ''constraints first'' take longer for a single refinement, as they call the strongest-post operator more often - for every abstract variable assignment and every constraint once, respectively.
The ''values only'' computation only calls the strongest-post operator once for every value, in contrast.
Similiarly, analyses using ''values only'' and ''values first'' are able to prove one more task safe then ''constraints first''.
This one is very close to the time limit (867.7 seconds using ''values only'', 836.6 seconds using ''values first''), too.

Analysis with interpolation using ''values first'' or ''constraints first'' is also able to prove one task safe ''values only'' can't.
Here, the computation times of 656.0 and 642.0 seconds are farther away from the time limit.
Although refinement takes longer then with ''values only'', the coarser precision of the \constraintsCPA\ speeds up termination of the analysis after all information necessary for proving all error paths is tracked.

For further evaluation we will use the ''constraints first'' technique, as it is the closest to our specification and does not pose any obvious disadvantages in comparison to the other two techniques.




